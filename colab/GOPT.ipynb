{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "GOPT",
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "14aqtNsj4ElEgPikGQZ88daFwxDJwElSK",
   "authorship_tag": "ABX9TyPsy+a4fQ7jWZcJttPSF8p/",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/YuanGongND/gopt/blob/master/colab/GOPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Step 1. Automatically load the Kaldi GOP feature. \n",
    "Note: this skips the Kaldi GOP feature extraction part. If you are interested in the feature extraction, please check our GitHub on how to do that."
   ],
   "metadata": {
    "id": "kKg-0_ISru4v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "print('current working dir is ' + os.getcwd())\n",
    "data_dir = os.getcwd() + '/gopt'\n",
    "if os.path.exists(data_dir) == True:\n",
    "    print('data path already exists')\n",
    "else:\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "if os.path.exists(os.getcwd() + '/gopt/data.zip') == False:\n",
    "  print('Downloading the intermediate GOP feature, please be patient.')\n",
    "  os.system('wget https://www.dropbox.com/s/zc6o1d8rqq28vci/data.zip?dl=1 -O ' + os.getcwd() +'/gopt/data.zip')\n",
    "  os.system('unzip -q ' + os.getcwd() + '/gopt/data.zip -d ' + os.getcwd() + '/gopt/')\n",
    "  print('Kaldi GOP features loaded at ' + os.getcwd() + '/gopt/, check the fold button on the left hand for details.')\n",
    "else:\n",
    "  print('Kaldi GOP features already loadedat ' + os.getcwd() + '/gopt/, check the fold button on the left hand for details.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqFES3mXuA2n",
    "outputId": "15ae550f-7571-470e-d576-0110ee94d3fd"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "current working dir is /content\n",
      "data path already exists\n",
      "Kaldi GOP features already loadedat /content/gopt/, check the fold button on the left hand for details.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2. Build the GOPT model."
   ],
   "metadata": {
    "id": "366AJg7CpXjP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I7bNAIRSoKDp"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# code from the t2t-vit paper\n",
    "def get_sinusoid_encoding(n_position, d_hid):\n",
    "    ''' Sinusoid position encoding table '''\n",
    "\n",
    "    def get_position_angle_vec(position):\n",
    "        return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
    "\n",
    "    sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "    return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
    "\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
    "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    def norm_cdf(x):\n",
    "        # Computes standard normal cumulative distribution function\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Values are generated by using a truncated uniform distribution and\n",
    "        # then using the inverse CDF for the normal distribution.\n",
    "        # Get upper and lower cdf values\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        # Uniformly fill tensor with values from [l, u], then translate to\n",
    "        # [2l-1, 2u-1].\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "\n",
    "        # Use inverse cdf transform for normal distribution to get truncated\n",
    "        # standard normal\n",
    "        tensor.erfinv_()\n",
    "\n",
    "        # Transform to proper mean, std\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "\n",
    "        # Clamp to ensure it's in the proper range\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        return tensor\n",
    "\n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        #print(C)\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "        self.drop_path = nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "# standard GOPT model proposed in the paper\n",
    "class GOPT(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, depth, input_dim=84):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        # Transformer encode blocks\n",
    "        self.blocks = nn.ModuleList([Block(dim=embed_dim, num_heads=num_heads) for i in range(depth)])\n",
    "\n",
    "        # sin pos embedding or learnable pos embedding, 55 = 50 sequence length + 5 utt-level cls tokens\n",
    "        #self.pos_embed = nn.Parameter(get_sinusoid_encoding(55, self.embed_dim) * 0.1, requires_grad=True)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, 55, self.embed_dim))\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "\n",
    "        # for phone classification\n",
    "        self.in_proj = nn.Linear(self.input_dim, embed_dim)\n",
    "        self.mlp_head_phn = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        # for word classification, 1=accuracy, 2=stress, 3=total\n",
    "        self.mlp_head_word1 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "        self.mlp_head_word2 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "        self.mlp_head_word3 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        # canonical phone projection, assume there are 40 phns\n",
    "        self.phn_proj = nn.Linear(40, embed_dim)\n",
    "\n",
    "        # utterance level, 1=accuracy, 2=completeness, 3=fluency, 4=prosodic, 5=total score\n",
    "        self.cls_token1 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.mlp_head_utt1 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "        self.cls_token2 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.mlp_head_utt2 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "        self.cls_token3 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.mlp_head_utt3 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "        self.cls_token4 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.mlp_head_utt4 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "        self.cls_token5 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.mlp_head_utt5 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        # initialize the cls tokens\n",
    "        trunc_normal_(self.cls_token1, std=.02)\n",
    "        trunc_normal_(self.cls_token2, std=.02)\n",
    "        trunc_normal_(self.cls_token3, std=.02)\n",
    "        trunc_normal_(self.cls_token4, std=.02)\n",
    "        trunc_normal_(self.cls_token5, std=.02)\n",
    "\n",
    "    # x shape in [batch_size, sequence_len, feat_dim]\n",
    "    # phn in [batch_size, seq_len]\n",
    "    def forward(self, x, phn):\n",
    "\n",
    "        # batch size\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # phn_one_hot in shape [batch_size, seq_len, feat_dim]\n",
    "        phn_one_hot = torch.nn.functional.one_hot(phn.long()+1, num_classes=40).float()\n",
    "        # phn_embed in shape [batch_size, seq_len, embed_dim]\n",
    "        phn_embed = self.phn_proj(phn_one_hot)\n",
    "\n",
    "        # if the input dimension is different from the Transformer embedding dimension, project the input to same dim\n",
    "        if self.embed_dim != self.input_dim:\n",
    "            x = self.in_proj(x)\n",
    "\n",
    "        x = x + phn_embed\n",
    "\n",
    "        cls_token1 = self.cls_token1.expand(B, -1, -1)\n",
    "        cls_token2 = self.cls_token2.expand(B, -1, -1)\n",
    "        cls_token3 = self.cls_token3.expand(B, -1, -1)\n",
    "        cls_token4 = self.cls_token4.expand(B, -1, -1)\n",
    "        cls_token5 = self.cls_token5.expand(B, -1, -1)\n",
    "\n",
    "        x = torch.cat((cls_token1, cls_token2, cls_token3, cls_token4, cls_token5, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "\n",
    "        # forward to the Transformer encoder\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        # the first 5 tokens are utterance-level cls tokens, i.e., accuracy, completeness, fluency, prosodic, total scores\n",
    "        u1 = self.mlp_head_utt1(x[:, 0])\n",
    "        u2 = self.mlp_head_utt2(x[:, 1])\n",
    "        u3 = self.mlp_head_utt3(x[:, 2])\n",
    "        u4 = self.mlp_head_utt4(x[:, 3])\n",
    "        u5 = self.mlp_head_utt5(x[:, 4])\n",
    "\n",
    "        # 6th-end tokens are phone score tokens\n",
    "        p = self.mlp_head_phn(x[:, 5:])\n",
    "\n",
    "        # word score is propagated to phone-level, so word output is also at phone-level.\n",
    "        # but different mlp heads are used, 1 = accuracy, 2 = stress, 3 = total\n",
    "        w1 = self.mlp_head_word1(x[:, 5:])\n",
    "        w2 = self.mlp_head_word2(x[:, 5:])\n",
    "        w3 = self.mlp_head_word3(x[:, 5:])\n",
    "        return u1, u2, u3, u4, u5, p, w1, w2, w3"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3. Load the GOP features."
   ],
   "metadata": {
    "id": "Xf9OIkR1pvE1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GoPDataset(Dataset):\n",
    "    def __init__(self, set, am='librispeech'):\n",
    "        # normalize the input to 0 mean and unit std.\n",
    "        if am=='librispeech':\n",
    "            dir='seq_data_librispeech'\n",
    "            norm_mean, norm_std = 3.203, 4.045\n",
    "        elif am=='paiia':\n",
    "            dir='seq_data_paiia'\n",
    "            norm_mean, norm_std = -0.652, 9.737\n",
    "        elif am=='paiib':\n",
    "            dir='seq_data_paiib'\n",
    "            norm_mean, norm_std = -0.516, 9.247\n",
    "        else:\n",
    "            raise ValueError('Acoustic Model Unrecognized.')\n",
    "\n",
    "        if set == 'train':\n",
    "            self.feat = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/tr_feat.npy'), dtype=torch.float)\n",
    "            self.phn_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/tr_label_phn.npy'), dtype=torch.float)\n",
    "            self.utt_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/tr_label_utt.npy'), dtype=torch.float)\n",
    "            self.word_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/tr_label_word.npy'), dtype=torch.float)\n",
    "        elif set == 'test':\n",
    "            self.feat = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/te_feat.npy'), dtype=torch.float)\n",
    "            self.phn_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/te_label_phn.npy'), dtype=torch.float)\n",
    "            self.utt_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/te_label_utt.npy'), dtype=torch.float)\n",
    "            self.word_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/te_label_word.npy'), dtype=torch.float)\n",
    "\n",
    "        # normalize the GOP feature using the training set mean and std (only count the valid token features, exclude the padded tokens).\n",
    "        self.feat = self.norm_valid(self.feat, norm_mean, norm_std)\n",
    "\n",
    "        # normalize the utt_label to 0-2 (same with phn score range)\n",
    "        self.utt_label = self.utt_label / 5\n",
    "        # the last dim is word_id, so not normalizing\n",
    "        self.word_label[:, :, 0:3] = self.word_label[:, :, 0:3] / 5\n",
    "        self.phn_label[:, :, 1] = self.phn_label[:, :, 1]\n",
    "\n",
    "    # only normalize valid tokens, not padded token\n",
    "    def norm_valid(self, feat, norm_mean, norm_std):\n",
    "        norm_feat = torch.zeros_like(feat)\n",
    "        for i in range(feat.shape[0]):\n",
    "            for j in range(feat.shape[1]):\n",
    "                if feat[i, j, 0] != 0:\n",
    "                    norm_feat[i, j, :] = (feat[i, j, :] - norm_mean) / norm_std\n",
    "                else:\n",
    "                    break\n",
    "        return norm_feat\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.feat.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # feat, phn_label, phn_id, utt_label, word_label\n",
    "        return self.feat[idx, :], self.phn_label[idx, :, 1], self.phn_label[idx, :, 0], self.utt_label[idx, :], self.word_label[idx, :]"
   ],
   "metadata": {
    "id": "Z5z2U2dTpuNQ"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4. Build the training and evaluation pipeline."
   ],
   "metadata": {
    "id": "dXHf-H1jvzOS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "print(\"I am process %s, running on %s: starting (%s)\" % (os.getpid(), os.uname()[1], time.asctime()))\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--exp-dir\", type=str, default=os.getcwd()+\"/exp/\", help=\"directory to dump experiments\")\n",
    "parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float, metavar='LR', help='initial learning rate')\n",
    "parser.add_argument(\"--n-epochs\", type=int, default=50, help=\"number of maximum training epochs\")\n",
    "parser.add_argument(\"--goptdepth\", type=int, default=3, help=\"depth of gopt models\")\n",
    "parser.add_argument(\"--goptheads\", type=int, default=1, help=\"heads of gopt models\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=25, help=\"training batch size\")\n",
    "parser.add_argument(\"--embed_dim\", type=int, default=24, help=\"gopt transformer embedding dimension\")\n",
    "parser.add_argument(\"--loss_w_phn\", type=float, default=1, help=\"weight for phoneme-level loss\")\n",
    "parser.add_argument(\"--loss_w_word\", type=float, default=1, help=\"weight for word-level loss\")\n",
    "parser.add_argument(\"--loss_w_utt\", type=float, default=1, help=\"weight for utterance-level loss\")\n",
    "parser.add_argument(\"--model\", type=str, default='gopt', help=\"name of the model\")\n",
    "parser.add_argument(\"--am\", type=str, default='paiia', help=\"name of the acoustic models\")\n",
    "parser.add_argument(\"--noise\", type=float, default=0., help=\"the scale of random noise added on the input GoP feature\")\n",
    "\n",
    "# just to generate the header for the result.csv\n",
    "def gen_result_header():\n",
    "    phn_header = ['epoch', 'phone_train_mse', 'phone_train_pcc', 'phone_test_mse', 'phone_test_pcc', 'learning rate']\n",
    "    utt_header_set = ['utt_train_mse', 'utt_train_pcc', 'utt_test_mse', 'utt_test_pcc']\n",
    "    utt_header_score = ['accuracy', 'completeness', 'fluency', 'prosodic', 'total']\n",
    "    word_header_set = ['word_train_pcc', 'word_test_pcc']\n",
    "    word_header_score = ['accuracy', 'stress', 'total']\n",
    "    utt_header, word_header = [], []\n",
    "    for dset in utt_header_set:\n",
    "        utt_header = utt_header + [dset+'_'+x for x in utt_header_score]\n",
    "    for dset in word_header_set:\n",
    "        word_header = word_header + [dset+'_'+x for x in word_header_score]\n",
    "    header = phn_header + utt_header + word_header\n",
    "    return header\n",
    "\n",
    "def train(audio_model, train_loader, test_loader, args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('running on ' + str(device))\n",
    "\n",
    "    # best_cum_mAP is checkpoint ensemble from the first epoch to the best epoch\n",
    "    best_epoch, best_mse = 0, 999\n",
    "    global_step, epoch = 0, 0\n",
    "    exp_dir = args.exp_dir\n",
    "\n",
    "    if not isinstance(audio_model, nn.DataParallel):\n",
    "        audio_model = nn.DataParallel(audio_model)\n",
    "\n",
    "    audio_model = audio_model.to(device)\n",
    "    # Set up the optimizer\n",
    "    trainables = [p for p in audio_model.parameters() if p.requires_grad]\n",
    "    print('Total parameter number is : {:.3f} k'.format(sum(p.numel() for p in audio_model.parameters()) / 1e3))\n",
    "    print('Total trainable parameter number is : {:.3f} k'.format(sum(p.numel() for p in trainables) / 1e3))\n",
    "    optimizer = torch.optim.Adam(trainables, args.lr, weight_decay=5e-7, betas=(0.95, 0.999))\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(range(10, 100, 5)), gamma=0.5, last_epoch=-1)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    print(\"current #steps=%s, #epochs=%s\" % (global_step, epoch))\n",
    "    print(\"start training...\")\n",
    "    result = np.zeros([args.n_epochs, 32])\n",
    "\n",
    "    while epoch < args.n_epochs:\n",
    "        audio_model.train()\n",
    "        for i, (audio_input, phn_label, phns, utt_label, word_label) in enumerate(train_loader):\n",
    "\n",
    "            audio_input = audio_input.to(device, non_blocking=True)\n",
    "            phn_label = phn_label.to(device, non_blocking=True)\n",
    "            utt_label = utt_label.to(device, non_blocking=True)\n",
    "            word_label = word_label.to(device, non_blocking=True)\n",
    "\n",
    "            # warmup\n",
    "            warm_up_step = 100\n",
    "            if global_step <= warm_up_step and global_step % 5 == 0:\n",
    "                warm_lr = (global_step / warm_up_step) * args.lr\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = warm_lr\n",
    "                #print('warm-up learning rate is {:f}'.format(optimizer.param_groups[0]['lr']))\n",
    "\n",
    "            # add random noise for augmentation.\n",
    "            noise = (torch.rand([audio_input.shape[0], audio_input.shape[1], audio_input.shape[2]]) - 1) * args.noise\n",
    "            noise = noise.to(device, non_blocking=True)\n",
    "            audio_input = audio_input + noise\n",
    "\n",
    "            #print(phns.shape)\n",
    "            u1, u2, u3, u4, u5, p, w1, w2, w3 = audio_model(audio_input, phns)\n",
    "\n",
    "            # filter out the padded tokens, only calculate the loss based on the valid tokens\n",
    "            # < 0 is a flag of padded tokens\n",
    "            mask = (phn_label>=0)\n",
    "            p = p.squeeze(2)\n",
    "            p = p * mask\n",
    "            phn_label = phn_label * mask\n",
    "\n",
    "            loss_phn = loss_fn(p, phn_label)\n",
    "\n",
    "            # avoid the 0 losses of the padded tokens impacting the performance\n",
    "            loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "            # utterance level loss, also mse\n",
    "            utt_preds = torch.cat((u1, u2, u3, u4, u5), dim=1)\n",
    "            loss_utt = loss_fn(utt_preds ,utt_label)\n",
    "\n",
    "            # word level loss\n",
    "            word_label = word_label[:, :, 0:3]\n",
    "            mask = (word_label>=0)\n",
    "            word_pred = torch.cat((w1,w2,w3), dim=2)\n",
    "            word_pred = word_pred * mask\n",
    "            word_label = word_label * mask\n",
    "            loss_word = loss_fn(word_pred, word_label)\n",
    "            loss_word = loss_word * (mask.shape[0] * mask.shape[1] * mask.shape[2]) / torch.sum(mask)\n",
    "\n",
    "            loss = args.loss_w_phn * loss_phn + args.loss_w_utt * loss_utt + args.loss_w_word * loss_word\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "\n",
    "        print('start validation of epoch {:d}'.format(epoch))\n",
    "\n",
    "        # ensemble results\n",
    "        # don't save prediction for the training set\n",
    "        tr_mse, tr_corr, tr_utt_mse, tr_utt_corr, tr_word_mse, tr_word_corr = validate(audio_model, train_loader, args, -1)\n",
    "        te_mse, te_corr, te_utt_mse, te_utt_corr, te_word_mse, te_word_corr = validate(audio_model, test_loader, args, best_mse)\n",
    "\n",
    "        print('Phone: Test MSE: {:.3f}, CORR: {:.3f}'.format(te_mse.item(), te_corr))\n",
    "        print('Utterance:, ACC: {:.3f}, COM: {:.3f}, FLU: {:.3f}, PROC: {:.3f}, Total: {:.3f}'.format(te_utt_corr[0], te_utt_corr[1], te_utt_corr[2], te_utt_corr[3], te_utt_corr[4]))\n",
    "        print('Word:, ACC: {:.3f}, Stress: {:.3f}, Total: {:.3f}'.format(te_word_corr[0], te_word_corr[1], te_word_corr[2]))\n",
    "\n",
    "        result[epoch, :6] = [epoch, tr_mse, tr_corr, te_mse, te_corr, optimizer.param_groups[0]['lr']]\n",
    "\n",
    "        result[epoch, 6:26] = np.concatenate([tr_utt_mse, tr_utt_corr, te_utt_mse, te_utt_corr])\n",
    "\n",
    "        result[epoch, 26:32] = np.concatenate([tr_word_corr, te_word_corr])\n",
    "\n",
    "        header = ','.join(gen_result_header())\n",
    "        np.savetxt(exp_dir + '/result.csv', result, delimiter=',', header=header, comments='')\n",
    "        print('-------------------validation finished-------------------')\n",
    "\n",
    "        if te_mse < best_mse:\n",
    "            best_mse = te_mse\n",
    "            best_epoch = epoch\n",
    "\n",
    "        if best_epoch == epoch:\n",
    "            if os.path.exists(\"%s/models/\" % (exp_dir)) == False:\n",
    "                os.mkdir(\"%s/models\" % (exp_dir))\n",
    "            torch.save(audio_model.state_dict(), \"%s/models/best_audio_model.pth\" % (exp_dir))\n",
    "\n",
    "        if global_step > warm_up_step:\n",
    "            scheduler.step()\n",
    "\n",
    "        #print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "        epoch += 1\n",
    "\n",
    "def validate(audio_model, val_loader, args, best_mse):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if not isinstance(audio_model, nn.DataParallel):\n",
    "        audio_model = nn.DataParallel(audio_model)\n",
    "    audio_model = audio_model.to(device)\n",
    "    audio_model.eval()\n",
    "\n",
    "    A_phn, A_phn_target = [], []\n",
    "    A_u1, A_u2, A_u3, A_u4, A_u5, A_utt_target = [], [], [], [], [], []\n",
    "    A_w1, A_w2, A_w3, A_word_target = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for i, (audio_input, phn_label, phns, utt_label, word_label) in enumerate(val_loader):\n",
    "            audio_input = audio_input.to(device)\n",
    "\n",
    "            # compute output\n",
    "            u1, u2, u3, u4, u5, p, w1, w2, w3 = audio_model(audio_input, phns)\n",
    "            p = p.to('cpu').detach()\n",
    "            u1, u2, u3, u4, u5 = u1.to('cpu').detach(), u2.to('cpu').detach(), u3.to('cpu').detach(), u4.to('cpu').detach(), u5.to('cpu').detach()\n",
    "            w1, w2, w3 = w1.to('cpu').detach(), w2.to('cpu').detach(), w3.to('cpu').detach()\n",
    "\n",
    "            A_phn.append(p)\n",
    "            A_phn_target.append(phn_label)\n",
    "\n",
    "            A_u1.append(u1)\n",
    "            A_u2.append(u2)\n",
    "            A_u3.append(u3)\n",
    "            A_u4.append(u4)\n",
    "            A_u5.append(u5)\n",
    "            A_utt_target.append(utt_label)\n",
    "\n",
    "            A_w1.append(w1)\n",
    "            A_w2.append(w2)\n",
    "            A_w3.append(w3)\n",
    "            A_word_target.append(word_label)\n",
    "\n",
    "        # phone level\n",
    "        A_phn, A_phn_target  = torch.cat(A_phn), torch.cat(A_phn_target)\n",
    "\n",
    "        # utterance level\n",
    "        A_u1, A_u2, A_u3, A_u4, A_u5, A_utt_target = torch.cat(A_u1), torch.cat(A_u2), torch.cat(A_u3), torch.cat(A_u4), torch.cat(A_u5), torch.cat(A_utt_target)\n",
    "\n",
    "        # word level\n",
    "        A_w1, A_w2, A_w3, A_word_target = torch.cat(A_w1), torch.cat(A_w2), torch.cat(A_w3), torch.cat(A_word_target)\n",
    "\n",
    "        # get the scores\n",
    "        phn_mse, phn_corr = valid_phn(A_phn, A_phn_target)\n",
    "\n",
    "        A_utt = torch.cat((A_u1, A_u2, A_u3, A_u4, A_u5), dim=1)\n",
    "        utt_mse, utt_corr = valid_utt(A_utt, A_utt_target)\n",
    "\n",
    "        A_word = torch.cat((A_w1, A_w2, A_w3), dim=2)\n",
    "        word_mse, word_corr, valid_word_pred, valid_word_target = valid_word(A_word, A_word_target)\n",
    "\n",
    "        if phn_mse < best_mse:\n",
    "            print('new best phn mse {:.3f}, now saving predictions.'.format(phn_mse))\n",
    "\n",
    "            # create the directory\n",
    "            if os.path.exists(args.exp_dir + '/preds') == False:\n",
    "                os.mkdir(args.exp_dir + '/preds')\n",
    "\n",
    "            # saving the phn target, only do once\n",
    "            if os.path.exists(args.exp_dir + '/preds/phn_target.npy') == False:\n",
    "                np.save(args.exp_dir + '/preds/phn_target.npy', A_phn_target)\n",
    "                np.save(args.exp_dir + '/preds/word_target.npy', valid_word_target)\n",
    "                np.save(args.exp_dir + '/preds/utt_target.npy', A_utt_target)\n",
    "\n",
    "            np.save(args.exp_dir + '/preds/phn_pred.npy', A_phn)\n",
    "            np.save(args.exp_dir + '/preds/word_pred.npy', valid_word_pred)\n",
    "            np.save(args.exp_dir + '/preds/utt_pred.npy', A_utt)\n",
    "\n",
    "    return phn_mse, phn_corr, utt_mse, utt_corr, word_mse, word_corr\n",
    "\n",
    "def valid_phn(audio_output, target):\n",
    "    valid_token_pred = []\n",
    "    valid_token_target = []\n",
    "    audio_output = audio_output.squeeze(2)\n",
    "    for i in range(audio_output.shape[0]):\n",
    "        for j in range(audio_output.shape[1]):\n",
    "            # only count valid tokens, not padded tokens (represented by negative values)\n",
    "            if target[i, j] >= 0:\n",
    "                valid_token_pred.append(audio_output[i, j])\n",
    "                valid_token_target.append(target[i, j])\n",
    "    valid_token_target = np.array(valid_token_target)\n",
    "    valid_token_pred = np.array(valid_token_pred)\n",
    "\n",
    "    valid_token_mse = np.mean((valid_token_target - valid_token_pred) ** 2)\n",
    "    corr = np.corrcoef(valid_token_pred, valid_token_target)[0, 1]\n",
    "    return valid_token_mse, corr\n",
    "\n",
    "def valid_utt(audio_output, target):\n",
    "    mse = []\n",
    "    corr = []\n",
    "    for i in range(5):\n",
    "        cur_mse = np.mean(((audio_output[:, i] - target[:, i]) ** 2).numpy())\n",
    "        cur_corr = np.corrcoef(audio_output[:, i], target[:, i])[0, 1]\n",
    "        mse.append(cur_mse)\n",
    "        corr.append(cur_corr)\n",
    "    return mse, corr\n",
    "\n",
    "def valid_word(audio_output, target):\n",
    "    word_id = target[:, :, -1]\n",
    "    target = target[:, :, 0:3]\n",
    "\n",
    "    valid_token_pred = []\n",
    "    valid_token_target = []\n",
    "\n",
    "    # unique, counts = np.unique(np.array(target), return_counts=True)\n",
    "    # print(dict(zip(unique, counts)))\n",
    "\n",
    "    # for each utterance\n",
    "    for i in range(target.shape[0]):\n",
    "        prev_w_id = 0\n",
    "        start_id = 0\n",
    "        # for each token\n",
    "        for j in range(target.shape[1]):\n",
    "            cur_w_id = word_id[i, j].int()\n",
    "            # if a new word\n",
    "            if cur_w_id != prev_w_id:\n",
    "                # average each phone belongs to the word\n",
    "                valid_token_pred.append(np.mean(audio_output[i, start_id: j, :].numpy(), axis=0))\n",
    "                valid_token_target.append(np.mean(target[i, start_id: j, :].numpy(), axis=0))\n",
    "                # sanity check, if the range indeed contains a single word\n",
    "                if len(torch.unique(target[i, start_id: j, 1])) != 1:\n",
    "                    print(target[i, start_id: j, 0])\n",
    "                # if end of the utterance\n",
    "                if cur_w_id == -1:\n",
    "                    break\n",
    "                else:\n",
    "                    prev_w_id = cur_w_id\n",
    "                    start_id = j\n",
    "\n",
    "    valid_token_pred = np.array(valid_token_pred)\n",
    "    # this rounding is to solve the precision issue in the label\n",
    "    valid_token_target = np.array(valid_token_target).round(2)\n",
    "\n",
    "    mse_list, corr_list = [], []\n",
    "    # for each (accuracy, stress, total) word score\n",
    "    for i in range(3):\n",
    "        valid_token_mse = np.mean((valid_token_target[:, i] - valid_token_pred[:, i]) ** 2)\n",
    "        corr = np.corrcoef(valid_token_pred[:, i], valid_token_target[:, i])[0, 1]\n",
    "        mse_list.append(valid_token_mse)\n",
    "        corr_list.append(corr)\n",
    "    return mse_list, corr_list, valid_token_pred, valid_token_target"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjCZLezhvxfB",
    "outputId": "93d64170-4a27-4236-d574-dcbaca5bb95c"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I am process 1460, running on 83b0eafbb5a9: starting (Fri May  6 06:21:04 2022)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5. Train the model and see the results!\n",
    "Note: due to various reasons, the colab result will be slightly different with (but still very close to) that using the local script. E.g., in this run, we get 0.685 phone-level PCC, 0.602 word-level PCC, and 0.729 utterance-level PCC, while in the paper, we report 0.679. 0.601, and 0.731, respectively. "
   ],
   "metadata": {
    "id": "UtIUrJo0OHEl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if torch.cuda.is_available() == False:\n",
    "    raise ValueError('GPU is not enabled. Please go to top menu - edit - notebook settings -hardware accelerator - GPU')\n",
    "\n",
    "am = args.am\n",
    "print('now train with {:s} acoustic models'.format(am))\n",
    "feat_dim = {'librispeech':84, 'paiia':86, 'paiib': 88}\n",
    "input_dim=feat_dim[am]\n",
    "\n",
    "# nowa is the best models used in this work\n",
    "if args.model == 'gopt':\n",
    "    print('now train a GOPT models')\n",
    "    audio_mdl = GOPT(embed_dim=args.embed_dim, num_heads=args.goptheads, depth=args.goptdepth, input_dim=input_dim)\n",
    "\n",
    "tr_dataset = GoPDataset('train', am=am)\n",
    "tr_dataloader = DataLoader(tr_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "te_dataset = GoPDataset('test', am=am)\n",
    "te_dataloader = DataLoader(te_dataset, batch_size=2500, shuffle=False)\n",
    "\n",
    "if os.path.exists(args.exp_dir) == False:\n",
    "  os.makedirs(args.exp_dir)\n",
    "train(audio_mdl, tr_dataloader, te_dataloader, args)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOEATqXrwkqn",
    "outputId": "e7581730-5128-4e68-f136-11f5e8482e4a"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "now train with paiia acoustic models\n",
      "now train a GOPT models\n",
      "running on cpu\n",
      "Total parameter number is : 26.625 k\n",
      "Total trainable parameter number is : 26.625 k\n",
      "current #steps=0, #epochs=0\n",
      "start training...\n",
      "start validation\n",
      "new best phn mse 0.101, now saving predictions.\n",
      "Phone: Test MSE: 0.101, CORR: 0.473\n",
      "Utterance:, ACC: 0.166, COM: 0.023, FLU: -0.005, PROC: -0.151, Total: 0.143\n",
      "Word:, ACC: 0.258, Stress: 0.077, Total: 0.333\n",
      "-------------------validation finished-------------------\n",
      "Epoch-0 lr: 0.00095\n",
      "start validation\n",
      "new best phn mse 0.096, now saving predictions.\n",
      "Phone: Test MSE: 0.096, CORR: 0.553\n",
      "Utterance:, ACC: 0.263, COM: 0.164, FLU: 0.217, PROC: -0.088, Total: 0.291\n",
      "Word:, ACC: 0.480, Stress: 0.130, Total: 0.522\n",
      "-------------------validation finished-------------------\n",
      "Epoch-1 lr: 0.001\n",
      "start validation\n",
      "new best phn mse 0.081, now saving predictions.\n",
      "Phone: Test MSE: 0.081, CORR: 0.606\n",
      "Utterance:, ACC: 0.456, COM: 0.200, FLU: 0.371, PROC: 0.183, Total: 0.498\n",
      "Word:, ACC: 0.539, Stress: 0.117, Total: 0.561\n",
      "-------------------validation finished-------------------\n",
      "Epoch-2 lr: 0.001\n",
      "start validation\n",
      "new best phn mse 0.074, now saving predictions.\n",
      "Phone: Test MSE: 0.074, CORR: 0.650\n",
      "Utterance:, ACC: 0.659, COM: 0.157, FLU: 0.590, PROC: 0.598, Total: 0.674\n",
      "Word:, ACC: 0.558, Stress: 0.106, Total: 0.566\n",
      "-------------------validation finished-------------------\n",
      "Epoch-3 lr: 0.001\n",
      "start validation\n",
      "Phone: Test MSE: 0.076, CORR: 0.653\n",
      "Utterance:, ACC: 0.689, COM: 0.220, FLU: 0.611, PROC: 0.612, Total: 0.692\n",
      "Word:, ACC: 0.562, Stress: 0.141, Total: 0.566\n",
      "-------------------validation finished-------------------\n",
      "Epoch-4 lr: 0.001\n",
      "start validation\n",
      "new best phn mse 0.073, now saving predictions.\n",
      "Phone: Test MSE: 0.073, CORR: 0.666\n",
      "Utterance:, ACC: 0.691, COM: 0.145, FLU: 0.605, PROC: 0.611, Total: 0.693\n",
      "Word:, ACC: 0.570, Stress: 0.118, Total: 0.569\n",
      "-------------------validation finished-------------------\n",
      "Epoch-5 lr: 0.001\n",
      "start validation\n",
      "new best phn mse 0.073, now saving predictions.\n",
      "Phone: Test MSE: 0.073, CORR: 0.673\n",
      "Utterance:, ACC: 0.695, COM: 0.096, FLU: 0.614, PROC: 0.616, Total: 0.700\n",
      "Word:, ACC: 0.575, Stress: 0.094, Total: 0.580\n",
      "-------------------validation finished-------------------\n",
      "Epoch-6 lr: 0.001\n",
      "start validation\n",
      "new best phn mse 0.069, now saving predictions.\n",
      "Phone: Test MSE: 0.069, CORR: 0.675\n",
      "Utterance:, ACC: 0.702, COM: 0.137, FLU: 0.621, PROC: 0.619, Total: 0.705\n",
      "Word:, ACC: 0.578, Stress: 0.129, Total: 0.585\n",
      "-------------------validation finished-------------------\n",
      "Epoch-7 lr: 0.001\n",
      "start validation\n",
      "Phone: Test MSE: 0.072, CORR: 0.671\n",
      "Utterance:, ACC: 0.711, COM: 0.163, FLU: 0.627, PROC: 0.620, Total: 0.710\n",
      "Word:, ACC: 0.576, Stress: 0.165, Total: 0.587\n",
      "-------------------validation finished-------------------\n",
      "Epoch-8 lr: 0.001\n",
      "start validation\n",
      "Phone: Test MSE: 0.075, CORR: 0.674\n",
      "Utterance:, ACC: 0.687, COM: 0.015, FLU: 0.619, PROC: 0.617, Total: 0.702\n",
      "Word:, ACC: 0.595, Stress: 0.100, Total: 0.607\n",
      "-------------------validation finished-------------------\n",
      "Epoch-9 lr: 0.001\n",
      "start validation\n",
      "Phone: Test MSE: 0.069, CORR: 0.677\n",
      "Utterance:, ACC: 0.712, COM: 0.138, FLU: 0.627, PROC: 0.618, Total: 0.710\n",
      "Word:, ACC: 0.578, Stress: 0.154, Total: 0.588\n",
      "-------------------validation finished-------------------\n",
      "Epoch-10 lr: 0.0005\n",
      "start validation\n",
      "new best phn mse 0.068, now saving predictions.\n",
      "Phone: Test MSE: 0.068, CORR: 0.683\n",
      "Utterance:, ACC: 0.714, COM: 0.050, FLU: 0.639, PROC: 0.637, Total: 0.718\n",
      "Word:, ACC: 0.586, Stress: 0.129, Total: 0.601\n",
      "-------------------validation finished-------------------\n",
      "Epoch-11 lr: 0.0005\n",
      "start validation\n",
      "Phone: Test MSE: 0.071, CORR: 0.678\n",
      "Utterance:, ACC: 0.720, COM: 0.109, FLU: 0.643, PROC: 0.640, Total: 0.720\n",
      "Word:, ACC: 0.580, Stress: 0.144, Total: 0.596\n",
      "-------------------validation finished-------------------\n",
      "Epoch-12 lr: 0.0005\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.682\n",
      "Utterance:, ACC: 0.722, COM: 0.066, FLU: 0.648, PROC: 0.646, Total: 0.723\n",
      "Word:, ACC: 0.583, Stress: 0.133, Total: 0.598\n",
      "-------------------validation finished-------------------\n",
      "Epoch-13 lr: 0.0005\n",
      "start validation\n",
      "new best phn mse 0.068, now saving predictions.\n",
      "Phone: Test MSE: 0.068, CORR: 0.683\n",
      "Utterance:, ACC: 0.718, COM: 0.070, FLU: 0.644, PROC: 0.643, Total: 0.721\n",
      "Word:, ACC: 0.591, Stress: 0.130, Total: 0.603\n",
      "-------------------validation finished-------------------\n",
      "Epoch-14 lr: 0.0005\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.684\n",
      "Utterance:, ACC: 0.725, COM: 0.061, FLU: 0.655, PROC: 0.653, Total: 0.725\n",
      "Word:, ACC: 0.590, Stress: 0.153, Total: 0.605\n",
      "-------------------validation finished-------------------\n",
      "Epoch-15 lr: 0.00025\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.683\n",
      "Utterance:, ACC: 0.725, COM: 0.044, FLU: 0.653, PROC: 0.650, Total: 0.724\n",
      "Word:, ACC: 0.582, Stress: 0.140, Total: 0.597\n",
      "-------------------validation finished-------------------\n",
      "Epoch-16 lr: 0.00025\n",
      "start validation\n",
      "new best phn mse 0.068, now saving predictions.\n",
      "Phone: Test MSE: 0.068, CORR: 0.684\n",
      "Utterance:, ACC: 0.726, COM: 0.059, FLU: 0.655, PROC: 0.653, Total: 0.726\n",
      "Word:, ACC: 0.586, Stress: 0.132, Total: 0.601\n",
      "-------------------validation finished-------------------\n",
      "Epoch-17 lr: 0.00025\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.685\n",
      "Utterance:, ACC: 0.721, COM: 0.027, FLU: 0.654, PROC: 0.654, Total: 0.724\n",
      "Word:, ACC: 0.591, Stress: 0.127, Total: 0.606\n",
      "-------------------validation finished-------------------\n",
      "Epoch-18 lr: 0.00025\n",
      "start validation\n",
      "new best phn mse 0.067, now saving predictions.\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.724, COM: 0.021, FLU: 0.655, PROC: 0.655, Total: 0.726\n",
      "Word:, ACC: 0.585, Stress: 0.120, Total: 0.600\n",
      "-------------------validation finished-------------------\n",
      "Epoch-19 lr: 0.00025\n",
      "start validation\n",
      "Phone: Test MSE: 0.069, CORR: 0.681\n",
      "Utterance:, ACC: 0.726, COM: 0.061, FLU: 0.657, PROC: 0.655, Total: 0.726\n",
      "Word:, ACC: 0.582, Stress: 0.135, Total: 0.596\n",
      "-------------------validation finished-------------------\n",
      "Epoch-20 lr: 0.000125\n",
      "start validation\n",
      "new best phn mse 0.067, now saving predictions.\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.036, FLU: 0.660, PROC: 0.659, Total: 0.728\n",
      "Word:, ACC: 0.590, Stress: 0.128, Total: 0.606\n",
      "-------------------validation finished-------------------\n",
      "Epoch-21 lr: 0.000125\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.686\n",
      "Utterance:, ACC: 0.723, COM: 0.008, FLU: 0.659, PROC: 0.659, Total: 0.727\n",
      "Word:, ACC: 0.591, Stress: 0.124, Total: 0.607\n",
      "-------------------validation finished-------------------\n",
      "Epoch-22 lr: 0.000125\n",
      "start validation\n",
      "new best phn mse 0.067, now saving predictions.\n",
      "Phone: Test MSE: 0.067, CORR: 0.686\n",
      "Utterance:, ACC: 0.727, COM: 0.023, FLU: 0.662, PROC: 0.662, Total: 0.728\n",
      "Word:, ACC: 0.590, Stress: 0.130, Total: 0.606\n",
      "-------------------validation finished-------------------\n",
      "Epoch-23 lr: 0.000125\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.684\n",
      "Utterance:, ACC: 0.727, COM: 0.034, FLU: 0.662, PROC: 0.663, Total: 0.728\n",
      "Word:, ACC: 0.589, Stress: 0.131, Total: 0.604\n",
      "-------------------validation finished-------------------\n",
      "Epoch-24 lr: 0.000125\n",
      "start validation\n",
      "Phone: Test MSE: 0.069, CORR: 0.685\n",
      "Utterance:, ACC: 0.719, COM: -0.012, FLU: 0.658, PROC: 0.659, Total: 0.725\n",
      "Word:, ACC: 0.594, Stress: 0.102, Total: 0.610\n",
      "-------------------validation finished-------------------\n",
      "Epoch-25 lr: 6.25e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.686\n",
      "Utterance:, ACC: 0.724, COM: -0.000, FLU: 0.662, PROC: 0.663, Total: 0.728\n",
      "Word:, ACC: 0.592, Stress: 0.119, Total: 0.608\n",
      "-------------------validation finished-------------------\n",
      "Epoch-26 lr: 6.25e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.726, COM: 0.013, FLU: 0.663, PROC: 0.663, Total: 0.728\n",
      "Word:, ACC: 0.588, Stress: 0.127, Total: 0.603\n",
      "-------------------validation finished-------------------\n",
      "Epoch-27 lr: 6.25e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.684\n",
      "Utterance:, ACC: 0.727, COM: 0.016, FLU: 0.663, PROC: 0.664, Total: 0.729\n",
      "Word:, ACC: 0.585, Stress: 0.129, Total: 0.601\n",
      "-------------------validation finished-------------------\n",
      "Epoch-28 lr: 6.25e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.726, COM: 0.013, FLU: 0.663, PROC: 0.664, Total: 0.728\n",
      "Word:, ACC: 0.588, Stress: 0.126, Total: 0.604\n",
      "-------------------validation finished-------------------\n",
      "Epoch-29 lr: 6.25e-05\n",
      "start validation\n",
      "new best phn mse 0.067, now saving predictions.\n",
      "Phone: Test MSE: 0.067, CORR: 0.686\n",
      "Utterance:, ACC: 0.723, COM: 0.002, FLU: 0.663, PROC: 0.664, Total: 0.727\n",
      "Word:, ACC: 0.591, Stress: 0.114, Total: 0.607\n",
      "-------------------validation finished-------------------\n",
      "Epoch-30 lr: 3.125e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.016, FLU: 0.665, PROC: 0.666, Total: 0.729\n",
      "Word:, ACC: 0.588, Stress: 0.125, Total: 0.604\n",
      "-------------------validation finished-------------------\n",
      "Epoch-31 lr: 3.125e-05\n",
      "start validation\n",
      "new best phn mse 0.067, now saving predictions.\n",
      "Phone: Test MSE: 0.067, CORR: 0.686\n",
      "Utterance:, ACC: 0.726, COM: 0.011, FLU: 0.665, PROC: 0.666, Total: 0.729\n",
      "Word:, ACC: 0.589, Stress: 0.120, Total: 0.605\n",
      "-------------------validation finished-------------------\n",
      "Epoch-32 lr: 3.125e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.684\n",
      "Utterance:, ACC: 0.727, COM: 0.021, FLU: 0.665, PROC: 0.666, Total: 0.729\n",
      "Word:, ACC: 0.584, Stress: 0.129, Total: 0.600\n",
      "-------------------validation finished-------------------\n",
      "Epoch-33 lr: 3.125e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.686\n",
      "Utterance:, ACC: 0.726, COM: 0.005, FLU: 0.666, PROC: 0.667, Total: 0.729\n",
      "Word:, ACC: 0.590, Stress: 0.120, Total: 0.606\n",
      "-------------------validation finished-------------------\n",
      "Epoch-34 lr: 3.125e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.011, FLU: 0.666, PROC: 0.667, Total: 0.729\n",
      "Word:, ACC: 0.588, Stress: 0.124, Total: 0.604\n",
      "-------------------validation finished-------------------\n",
      "Epoch-35 lr: 1.5625e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.684\n",
      "Utterance:, ACC: 0.727, COM: 0.017, FLU: 0.666, PROC: 0.667, Total: 0.729\n",
      "Word:, ACC: 0.586, Stress: 0.126, Total: 0.601\n",
      "-------------------validation finished-------------------\n",
      "Epoch-36 lr: 1.5625e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.010, FLU: 0.667, PROC: 0.668, Total: 0.729\n",
      "Word:, ACC: 0.588, Stress: 0.123, Total: 0.604\n",
      "-------------------validation finished-------------------\n",
      "Epoch-37 lr: 1.5625e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.684\n",
      "Utterance:, ACC: 0.727, COM: 0.013, FLU: 0.667, PROC: 0.668, Total: 0.729\n",
      "Word:, ACC: 0.586, Stress: 0.125, Total: 0.601\n",
      "-------------------validation finished-------------------\n",
      "Epoch-38 lr: 1.5625e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.726, COM: 0.004, FLU: 0.667, PROC: 0.668, Total: 0.729\n",
      "Word:, ACC: 0.589, Stress: 0.122, Total: 0.605\n",
      "-------------------validation finished-------------------\n",
      "Epoch-39 lr: 1.5625e-05\n",
      "start validation\n",
      "Phone: Test MSE: 0.068, CORR: 0.684\n",
      "Utterance:, ACC: 0.727, COM: 0.015, FLU: 0.667, PROC: 0.668, Total: 0.729\n",
      "Word:, ACC: 0.585, Stress: 0.127, Total: 0.601\n",
      "-------------------validation finished-------------------\n",
      "Epoch-40 lr: 7.8125e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.010, FLU: 0.667, PROC: 0.668, Total: 0.729\n",
      "Word:, ACC: 0.587, Stress: 0.123, Total: 0.603\n",
      "-------------------validation finished-------------------\n",
      "Epoch-41 lr: 7.8125e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.007, FLU: 0.667, PROC: 0.669, Total: 0.729\n",
      "Word:, ACC: 0.588, Stress: 0.122, Total: 0.604\n",
      "-------------------validation finished-------------------\n",
      "Epoch-42 lr: 7.8125e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.010, FLU: 0.667, PROC: 0.668, Total: 0.729\n",
      "Word:, ACC: 0.587, Stress: 0.124, Total: 0.603\n",
      "-------------------validation finished-------------------\n",
      "Epoch-43 lr: 7.8125e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.009, FLU: 0.668, PROC: 0.669, Total: 0.729\n",
      "Word:, ACC: 0.587, Stress: 0.124, Total: 0.603\n",
      "-------------------validation finished-------------------\n",
      "Epoch-44 lr: 7.8125e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.008, FLU: 0.668, PROC: 0.669, Total: 0.729\n",
      "Word:, ACC: 0.587, Stress: 0.124, Total: 0.602\n",
      "-------------------validation finished-------------------\n",
      "Epoch-45 lr: 3.90625e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.008, FLU: 0.668, PROC: 0.669, Total: 0.729\n",
      "Word:, ACC: 0.587, Stress: 0.123, Total: 0.603\n",
      "-------------------validation finished-------------------\n",
      "Epoch-46 lr: 3.90625e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.009, FLU: 0.668, PROC: 0.669, Total: 0.729\n",
      "Word:, ACC: 0.587, Stress: 0.124, Total: 0.603\n",
      "-------------------validation finished-------------------\n",
      "Epoch-47 lr: 3.90625e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.009, FLU: 0.668, PROC: 0.669, Total: 0.729\n",
      "Word:, ACC: 0.587, Stress: 0.123, Total: 0.603\n",
      "-------------------validation finished-------------------\n",
      "Epoch-48 lr: 3.90625e-06\n",
      "start validation\n",
      "Phone: Test MSE: 0.067, CORR: 0.685\n",
      "Utterance:, ACC: 0.727, COM: 0.009, FLU: 0.668, PROC: 0.669, Total: 0.729\n",
      "Word:, ACC: 0.586, Stress: 0.123, Total: 0.602\n",
      "-------------------validation finished-------------------\n",
      "Epoch-49 lr: 3.90625e-06\n"
     ]
    }
   ]
  }
 ]
}